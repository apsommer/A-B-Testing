{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "A/B tests are commonly performed by data analysts and data scientists. Therefore, it is important to practice these analyses. For this project the results of an A/B test completed by an e-commerce website is considered. The goal is to help the company understand if they should implement the new page, keep the old page, or run the experiment longer before making their decision.\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "#### Introduction\n",
    "##### Install Anaconda, open terminal, and isolate project in its own environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~ $ conda create -n proj4 ... create a new environment to isolate project dependencies`\n",
    "\n",
    "`~ $ source activate proj4 ... enter environment`\n",
    "\n",
    "`~ $ conda install python=3 numpy pandas matplotlib statsmodels ... install required packages`\n",
    "\n",
    "`~ $ conda env export > environment.yaml ... write project dependencies to conda specific file`\n",
    "\n",
    "`~ $ pip freeze > requirements.txt ... write project dependencies to generic file`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 'magic keyword' with % symbol interacts with this notebook\n",
    "# plot inline with cells rather than a separate window\n",
    "% matplotlib inline\n",
    "\n",
    "# set the random seed to assure repeatability of results\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, read in the `ab_data.csv` data. Store it in `df`.\n",
    "\n",
    "a. Take a look at the top few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset in dataframe object\n",
    "df = pd.read_csv('ab_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique users\n",
    "unique_users = df.user_id.nunique()\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12104245244060237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of users converted\n",
    "unique_user_conversions = df.user_id[(df.converted == 1)].nunique()\n",
    "prop_conversions = unique_user_conversions / unique_users\n",
    "prop_conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control', 'treatment'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group classifications\n",
    "df.group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['old_page', 'new_page'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# landing page classifications\n",
    "df.landing_page.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times 'new_page' and 'treatment' do not align\n",
    "# two scenarios where this occurs\n",
    "control_new_page = df[(df.group == 'control') & (df.landing_page == 'new_page')]\n",
    "treatment_old_page = df[(df.group == 'treatment') & (df.landing_page == 'old_page')]\n",
    "\n",
    "# add the occurances of both scenarios together\n",
    "control_new_page.shape[0] + treatment_old_page.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**None of the rows have missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page. Store your new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the index of each df subset as the timestamp column\n",
    "control_new_page.set_index('timestamp')\n",
    "treatment_old_page.set_index('timestamp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df2 by dropping a subset out of df\n",
    "df2 = df.drop(index = control_new_page.index)\n",
    "\n",
    "# further refine df2 by dropping a subset out of itself\n",
    "df2 = df2.drop(index = treatment_old_page.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use **df2** and the cells below to continue the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique users\n",
    "unique_users = df2.user_id.nunique()\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a boolean mask to isolate the duplicate user_id row\n",
    "mask = df2.user_id.duplicated()\n",
    "df2.user_id[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full rows for the duplicate user_id\n",
    "df2[df2.user_id == 773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one of the duplicate rows (default is first duplicate occurance at row 2893)\n",
    "df2.drop_duplicates(subset = 'user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row 2893 has been removed\n",
    "df2[df2.user_id == 773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use **df2** in the below cells to continue the analysis.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converstion rate regardless of any feature\n",
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conversion rate of control group\n",
    "full_p_old = df2.converted[df2.group == 'control'].mean()\n",
    "full_p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conversion rate of treatment group\n",
    "full_p_new = df2.converted[df2.group == 'treatment'].mean()\n",
    "full_p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50006194422266881"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of users who viewed the new landing page\n",
    "(df2.landing_page == 'new_page').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Is there evidence that one page leads to more conversions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50.0% of the dataset received the new landing page as the treatment group, and the other 50.0% was the control group. The treatment group's conversion rate with the new page was 11.9%, while the control group with the old page converted at 12.0%. These rates are within 0.1%, indicating at first glance there is no significant evidence either landing page is better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Due to the time stamp associated with each event, it is possible to run a hypothesis test continuously for each observation. However, when do we stop ... as soon as one page is considered significantly better than another, or does it need to happen consistently for a certain amount of time? How long do we continue to render a decision that neither page is better than another? In general, these questions are the difficult trades associated with A/B tests.\n",
    "\n",
    "`1.` For now, consider the decision must be made only with the data provided. Assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%. What should the null and alternative hypotheses be?  State the hypothesis in terms of $p_{old}$ and $p_{new}$, which are defined as the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$H_0: p_{old} >= p_{new}$**\n",
    "\n",
    "**$H_1: p_{old} < p_{new}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in `ab_data.csv` regardless of the page. <br><br>\n",
    "\n",
    "Use a sample size for each page equal to the ones in `ab_data.csv`. Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null. Use the cells below to provide the necessary parts of this simulation.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **convert rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assume p_new is equal to the conversion rate regardless of landing page\n",
    "p_new = df2.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **convert rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assume p_old = p_new for this null\n",
    "p_old = p_new\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total occurances of the new landing page\n",
    "n_new = (df2.landing_page == 'new_page').sum()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total occurances of the old landing page\n",
    "n_old = (df2.landing_page == 'old_page').sum()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose either 0 or 1 with a probability of p_new, a total of n_new times\n",
    "new_page_converted = np.random.choice([0, 1], size = n_new, p = [1 - p_new, p_new])\n",
    "p_new_sim = new_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose either 0 or 1 with a probability of p_old, a total of n_old times\n",
    "old_page_converted = np.random.choice([0, 1], size = n_old, p = [1 - p_old, p_old])\n",
    "p_old_sim = old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018424902461277731"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract the simulated values for p_old from p_new\n",
    "diff = p_new_sim - p_old_sim\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Simulate 10,000 $p_{new}$ - $p_{old}$ values using this same process similarly to the one you calculated in parts **a. through g.** above.  Store all 10,000 values in **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same logic above encapulated in a loop with 10000 iterations\n",
    "# this will create a sampling distribution without bootstraping\n",
    "# for the difference in page conversions under the null assumption H0: p_new = p_old\n",
    "p_diffs = []\n",
    "for _ in range(10000):\n",
    "    \n",
    "    # choose either 0 or 1 with a probability of p_new (= p_old), a total of n_new (or n_old) times\n",
    "    new_page_converted = np.random.choice([0, 1], size = n_new, p = [1 - p_new, p_new])\n",
    "    old_page_converted = np.random.choice([0, 1], size = n_old, p = [1 - p_old, p_old])\n",
    "\n",
    "    # probability of conversions\n",
    "    p_new_sim = new_page_converted.mean()\n",
    "    p_old_sim = old_page_converted.mean()\n",
    "    \n",
    "    # compute difference in means\n",
    "    p_diffs.append(p_new_sim - p_old_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**. Does this plot have the expected shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert python list to numpy array\n",
    "p_diffs = np.array(p_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual value of statistic from full dataset\n",
    "full_diff = full_p_new - full_p_old\n",
    "full_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8ee5c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of null distribution\n",
    "plt.hist(p_diffs);\n",
    "\n",
    "# plot actual statistic over null distribution\n",
    "plt.axvline(x = full_diff, color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a normal distribution of the simulated null hypothesis. Since the null hypothesis is that the two page conversion rates are equal, the difference between them is zero, and the distribution mean is therefore zero. The actual statistic from the data is slightly left of the mean at -0.00158. Although this is a few standard deviations from the mean at zero, it is plausible that this statistic came from the null hypothesis, and therefore we will not reject $H_0$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90839999999999999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# region from the red line to the extereme right side of the distribution\n",
    "upper_region = (p_diffs > full_diff).mean()\n",
    "\n",
    "# p-value = total shaded region\n",
    "p_value = upper_region\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. In words, explain what was computed in part **j.**.  What is this value called in scientific studies?  What does this value mean in terms of whether or not there is a difference between the new and old pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the p-value. The p-value is the probability of observing a statistic of interest, or one more extreme, given that the null hypothesis is true. To represent the null hypothesis, a normal distribution with mean of zero and standard deviation equal to the standard deviation of the original sample is plotted. The observed statistic, in this case the difference in mean conversion rates of the two pages, is placed on this plot. The statistic falls a few standard deviations to left of the mean, and since our alternate hypothesis $H_1: p_{new} - p_{old} > 0$, the p-value encompasses the region to the right of this line, almost the entire distribution. In other words, we fail to reject the null hypothesis as p-value = 0.91 is much greater than our Type I Error threshold of $\\alpha = 0.05$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in function to achieve similar results. Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statistics package\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# total number of conversions in the dataset\n",
    "convert_old = df2.converted[df.landing_page == 'old_page'].sum()\n",
    "convert_new = df2.converted[df.landing_page == 'new_page'].sum()\n",
    "# n_old and n_new were calculated previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](http://knowledgetack.com/python/statsmodels/proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate p-value and z-score using built-in\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative='larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.90505831275902449, -1.3109241984234394)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results to notebook\n",
    "p_value, z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value mean for the conversion rates of the old and new pages? Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The p-value obtained by proportions_ztest() is very similar to that obtained by direct simulation of the null hypothesis. Since the p-value >> $\\alpha$ we fail to reject the null hypothesis. The z-score indicates the number of standard deviations the statistic is from the null hypothesis mean. As shown by the red line in the plot above, the statistic is -1.31 standard deviations from the null hypothesis mean of zero. The output of the built-in function matches the direct simulation results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, the result achieved in the previous A/B test will also be achieved by performing regression.<br><br>\n",
    "\n",
    "a. Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use `statsmodels` to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives.  However, first we need to create a column for the intercept, and a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column for the intercept with an arbitrary value\n",
    "df2['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables for the landing_page feature\n",
    "df2[['old_page', 'ab_page']] = pd.get_dummies(df['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  old_page  ab_page  \n",
       "0          1         1        0  \n",
       "1          1         1        0  \n",
       "2          1         0        1  \n",
       "3          1         0        1  \n",
       "4          1         1        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unessecary columns\n",
    "df2.drop(['group', 'landing_page', 'old_page'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to import the regression model.  Instantiate the model, and fit the model using the two columns created in part **b.** to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the response y vector\n",
    "y = df2['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the predictor X matrix\n",
    "X = df2[['intercept', 'ab_page']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logistic regression using statsmodels\n",
    "log_model = sm.Logit(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "fit = log_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 28 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:24:01</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Fri, 28 Sep 2018   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        15:24:01   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print summary of regression parameters\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with **ab_page**? Why does it differ from the value found in **Part II**? What are the null and alternative hypotheses associated with the regression model, and how do they compare to the null and alternative hypotheses in **Part II**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The p-value associated with the landing page is 0.190, which is greater than the Type I Error threshold of $\\alpha$ = 0.05. Therefore, we again fail to reject the null hypothesis. The null hypothesis of a $\\beta$ coefficient in logistic regression is that the variable does not have a statistically signficant effect on the odds of response occuring, holding all other variables constant. In this case, $H_1$ is that the landing page the user observes changes the odds that they will convert, holding all other variables constant. With p-value > $\\alpha$ we conclude that $H_0$ is true; that the type of landing page does not have a significant effect on user conversion, holding all other variables constant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, consider other influences on individual converions.  Discuss why it is a good idea to consider other factors to add into the regression model.  Are there any disadvantages to adding additional terms into the regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In general, a scientific model should include all factors that have significant influence on the response ... and nothing else. In other words, the model should have the bare minimum complexity in order to adequately describe the event. We can consider other factors if there is reason to believe the explanatory and response variables are related in more complicated ways, for example a quadratic, cubic, interaction, etc. Including these higher order terms destroys the intuitive representation of the $\\beta$ coefficients. The intuitive explanations of these coefficients are valuable with respect to understanding the data and communicating the results. Without clear evidence of a higher order relationship the coefficients should remain against simple linear single variables in the logistic regression equations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. Read in the `countries.csv` dataset and merge together the datasets on the appropriate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "Does it appear that country had an impact on conversion? Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import table of countries\n",
    "df_c = pd.read_csv('countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp  converted  intercept  ab_page\n",
       "0   851104  2017-01-21 22:11:48.556739          0          1        0\n",
       "1   804228  2017-01-12 08:01:45.159739          0          1        0\n",
       "2   661590  2017-01-11 16:55:06.154213          0          1        1\n",
       "3   853541  2017-01-08 18:28:03.143765          0          1        1\n",
       "4   864975  2017-01-21 01:52:26.210827          1          1        0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a common index, then merge this country column into df2\n",
    "df2.set_index('user_id', inplace = True)\n",
    "df_c.set_index('user_id', inplace = True)\n",
    "df2 = df2.join(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies from categorical variable 'country'\n",
    "country_dummies = pd.get_dummies(df2['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these dummies into df2\n",
    "df2 = df2.join(country_dummies);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unessecary columns\n",
    "df2.drop(['UK', 'country'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  converted  intercept  ab_page  CA  US\n",
       "user_id                                                                   \n",
       "851104   2017-01-21 22:11:48.556739          0          1        0   0   1\n",
       "804228   2017-01-12 08:01:45.159739          0          1        0   0   1\n",
       "661590   2017-01-11 16:55:06.154213          0          1        1   0   1\n",
       "853541   2017-01-08 18:28:03.143765          0          1        1   0   1\n",
       "864975   2017-01-21 01:52:26.210827          1          1        0   0   1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the response y vector\n",
    "y = df2['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the predictor X matrix\n",
    "X = df2[['intercept', 'ab_page', 'CA', 'US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logistic regression using statsmodels\n",
    "log_model = sm.Logit(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "fit = log_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 28 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:24:03</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9794</td> <td>    0.013</td> <td> -155.415</td> <td> 0.000</td> <td>   -2.004</td> <td>   -1.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0506</td> <td>    0.028</td> <td>   -1.784</td> <td> 0.074</td> <td>   -0.106</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>   -0.0099</td> <td>    0.013</td> <td>   -0.743</td> <td> 0.457</td> <td>   -0.036</td> <td>    0.016</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Fri, 28 Sep 2018   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        15:24:03   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9794      0.013   -155.415      0.000      -2.004      -1.954\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0506      0.028     -1.784      0.074      -0.106       0.005\n",
       "US            -0.0099      0.013     -0.743      0.457      -0.036       0.016\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print summary of regression parameters\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the p-values for the countries (and one state) are less than $\\alpha$ = 0.05. Therefore, the user's location does not have a statistically significant effect on whether or not they convert. However, the coefficient for CA has a p-value of 0.074.**\n",
    "\n",
    "**Note: If the Type I Error rate for this analysis were relaxed, for example to $\\alpha$ = 0.1, then the following statement would be true: A user located in CA is 1/exp(-0.0506) = 1.05 = 5% less likely to convert than a user from the UK, keeping the landing page constant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Consider an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results and conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  converted  intercept  ab_page  CA  US\n",
       "user_id                                                                   \n",
       "851104   2017-01-21 22:11:48.556739          0          1        0   0   1\n",
       "804228   2017-01-12 08:01:45.159739          0          1        0   0   1\n",
       "661590   2017-01-11 16:55:06.154213          0          1        1   0   1\n",
       "853541   2017-01-08 18:28:03.143765          0          1        1   0   1\n",
       "864975   2017-01-21 01:52:26.210827          1          1        0   0   1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns for the interaction of country and landing page\n",
    "df2['ab_page*CA'] = df2.ab_page*df2.CA\n",
    "df2['ab_page*US'] = df2.ab_page*df2.US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>US</th>\n",
       "      <th>ab_page*CA</th>\n",
       "      <th>ab_page*US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  converted  intercept  ab_page  CA  US  \\\n",
       "user_id                                                                      \n",
       "851104   2017-01-21 22:11:48.556739          0          1        0   0   1   \n",
       "804228   2017-01-12 08:01:45.159739          0          1        0   0   1   \n",
       "661590   2017-01-11 16:55:06.154213          0          1        1   0   1   \n",
       "853541   2017-01-08 18:28:03.143765          0          1        1   0   1   \n",
       "864975   2017-01-21 01:52:26.210827          1          1        0   0   1   \n",
       "\n",
       "         ab_page*CA  ab_page*US  \n",
       "user_id                          \n",
       "851104            0           0  \n",
       "804228            0           0  \n",
       "661590            0           1  \n",
       "853541            0           1  \n",
       "864975            0           0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the response y vector\n",
    "y = df2['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the predictor X matrix\n",
    "X = df2[['intercept', 'ab_page', 'CA', 'US', 'ab_page*CA', 'ab_page*US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logistic regression using statsmodels\n",
    "log_model = sm.Logit(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "fit = log_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 28 Sep 2018</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:24:06</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -1.9922</td> <td>    0.016</td> <td> -123.457</td> <td> 0.000</td> <td>   -2.024</td> <td>   -1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>    0.0108</td> <td>    0.023</td> <td>    0.475</td> <td> 0.635</td> <td>   -0.034</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>         <td>   -0.0118</td> <td>    0.040</td> <td>   -0.296</td> <td> 0.767</td> <td>   -0.090</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>         <td>    0.0057</td> <td>    0.019</td> <td>    0.306</td> <td> 0.760</td> <td>   -0.031</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page*CA</th> <td>   -0.0783</td> <td>    0.057</td> <td>   -1.378</td> <td> 0.168</td> <td>   -0.190</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page*US</th> <td>   -0.0314</td> <td>    0.027</td> <td>   -1.181</td> <td> 0.238</td> <td>   -0.084</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Fri, 28 Sep 2018   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        15:24:06   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9922      0.016   -123.457      0.000      -2.024      -1.961\n",
       "ab_page        0.0108      0.023      0.475      0.635      -0.034       0.056\n",
       "CA            -0.0118      0.040     -0.296      0.767      -0.090       0.066\n",
       "US             0.0057      0.019      0.306      0.760      -0.031       0.043\n",
       "ab_page*CA    -0.0783      0.057     -1.378      0.168      -0.190       0.033\n",
       "ab_page*US    -0.0314      0.027     -1.181      0.238      -0.084       0.021\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print summary of regression parameters\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The interaction term has still not produced a statistically significant result as p-values for all regression terms are less than the Type I Error threshold $\\alpha$ = 0.05. The conversion rates of the two websites are so closely aligned that it is difficult to find a valid predictor variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-01-02 13:42:05.378582', '2017-01-24 13:41:54.460509')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total experiment time\n",
    "min(df2.timestamp), max(df2.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusion\n",
    "\n",
    "**The new landing page does not have a statistically significant affect on user conversion rate. Virtually no change is observed between the conversion rates of the old and new websites. This A/B test was conducted for 22 days in January 2017. If a decision must be made now, the recommendation is to continue with the existing website. Running the experiment for a longer duration (for example three months) may provide statistically significant patterns that are hidden in the rather short length of the current experiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert notebook to HTML for universal sharing ...\n",
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
